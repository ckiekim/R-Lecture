library(KoNLP)  # 필수 패키지 로딩
library(wordcloud) # 필수 패키지 로딩
useSejongDic( )
install.packages("stringr")
install.packages("dplyr")
install.packages("dply")
install.packages("ggplot2")
install.packages("KoNLP")
install.packages("sqldf")
install.packages("wordcloud")
library(KoNLP)  # 필수 패키지 로딩
library(wordcloud) # 필수 패키지 로딩
useSejongDic( )
setwd("D:\Workspace\R_Data_Analysis\Part2\P02_HS_Girls")
setwd("D:/Workspace/R_Data_Analysis/Part2/P02_HS_Girls")
data1 <- readLines("remake.txt")
library(KoNLP)  # 필수 패키지 로딩
library(wordcloud) # 필수 패키지 로딩
useSejongDic( )
data1 <- readLines("remake.txt")
data1
data2 <- sapply(data1,extractNoun,USE.NAMES=F)
data2
data3 <- unlist(data2)
data3 <- Filter(function(x) {nchar(x) <= 10} ,data3)
head(unlist(data3), 30)
data3 <- gsub("\\d+","", data3)
data3 <- gsub("쌍수","쌍꺼풀",data3)
data3 <- gsub("쌍커풀","쌍꺼풀",data3)
data3 <- gsub("메부리코","매부리코",data3)
data3 <- gsub("\\.","",data3)
data3 <- gsub(" ","",data3)
data3 <- gsub("\\'","",data3)
write(unlist(data3),"remake_2.txt")
data4 <- read.table("remake_2.txt")
data4
nrow(data4)
wordcount <- table(data4)
wordcount
head(sort(wordcount, decreasing=T),20)
txt <- readLines("성형gsub.txt")
cnt_txt <- length(txt)
cnt_txt
i <- 1
for( i in 1:cnt_txt) {
data3 <-gsub((txt[i]),"",data3)
}
library(RColorBrewer)
palete <- brewer.pal(9,"Set3")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=2,
random.order=F,random.color=T,colors=palete)
legend(0.3,1 ,"여고생들이 선호하는 성형수술 부위",
cex=0.8,fill=NA,border=NA,bg="white" ,
text.col="red",text.font=2,box.col="red")
library(KoNLP)  # 필수 패키지 로딩
library(wordcloud) # 필수 패키지 로딩
useSejongDic( )
setwd("D:/Workspace/R_Data_Analysis/Part2/P02_HS_Girls")
data1 <- readLines("remake.txt")
data1
data2 <- sapply(data1,extractNoun,USE.NAMES=F)
data2
data3 <- unlist(data2)
data3 <- Filter(function(x) {nchar(x) <= 10} ,data3)
head(unlist(data3), 30)
data3 <- gsub("\\d+","", data3)
data3 <- gsub("쌍수","쌍꺼풀",data3)
data3 <- gsub("쌍커풀","쌍꺼풀",data3)
data3 <- gsub("메부리코","매부리코",data3)
data3 <- gsub("\\.","",data3)
data3 <- gsub(" ","",data3)
data3 <- gsub("\\'","",data3)
data3
write(unlist(data3),"remake_2.txt")
data4 <- read.table("remake_2.txt")
data4
nrow(data4)
wordcount <- table(data4)
wordcount
head(sort(wordcount, decreasing=T),20)
txt <- readLines("성형gsub.txt")
cnt_txt <- length(txt)
cnt_txt
i <- 1
for( i in 1:cnt_txt) {
data3 <-gsub((txt[i]),"",data3)
}
library(RColorBrewer)
palete <- brewer.pal(9,"Set3")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=2,
random.order=F,random.color=T,colors=palete)
library(stringr)
mergeUserDic(data.frame(readLines('제주도여행지.txt'), 'ncn'))
txt <- readLines("jeju.txt")
txt
place <- sapply(txt,extractNoun,USE.NAMES=F)
place
head(unlist(place), 30)
cdata <- unlist(place)
place <- str_replace_all(cdata,"[^[:alpha:]]","")
place <- gsub(" ","", place)
txt <- readLines("제주도여행코스gsub.txt")
cnt_txt <- length(txt)
cnt_txt
for(i in 1:cnt_txt) {
place <-gsub((txt[i]),"",place)
}
place
place <- Filter(function(x) {nchar(x) >= 2} ,place)
place
write(unlist(place),"jeju_2.txt")
rev <- read.table("jeju_2.txt")
nrow(rev)
wordcount <- table(rev)
head(sort(wordcount, decreasing=T),30)
library(RColorBrewer)
palete <- brewer.pal(9,"Set1")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=2,
random.order=F,random.color=T,colors=palete)
legend(0.3,1 ,"제주도 추천 여행 코스 분석   ",cex=0.8,fill=NA,border=NA,bg="white" ,
text.col="red",text.font=2,box.col="red")
wordcount
str(wordcount)
install.packages('tm')
library(tm)
stopwords()
data1 <- readLines("tm_test1.txt")
data1
class(data1)
corp1 <- Corpus(VectorSource(data1))
corp1
inspect(corp1)
inspect(corp1)
tdm <- TermDocumentMatrix(corp1)
tdm
m <- as.matrix(tdm)
m
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,removePunctuation)
corp2 <- tm_map(corp2,PlainTextDocument)
sword2 <- c(stopwords('en'),"and","but",'not')
corp2 <- tm_map(corp2,removeWords,sword2)
corp2
tdm2 <- TermDocumentMatrix(corp2)
tdm2
m <- as.matrix(tdm)
m
tdm2 <- TermDocumentMatrix(corp1)
tdm2
corp2 <- tm_map(corp1,stripWhitespace)
TermDocumentMatrix(corp2)
corp2 <- tm_map(corp2,tolower)
TermDocumentMatrix(corp2)
corp2 <- tm_map(corp2,removeNumbers)
TermDocumentMatrix(corp2)
corp2 <- tm_map(corp2,removePunctuation)
TermDocumentMatrix(corp2)
corp2 <- tm_map(corp2,PlainTextDocument)
TermDocumentMatrix(corp2)
corp2 <- tm_map(corp1,stripWhitespace)
TermDocumentMatrix(corp2)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,removePunctuation)
#corp2 <- tm_map(corp2,PlainTextDocument)
sword2 <- c(stopwords('en'),"and","but",'not')
corp2 <- tm_map(corp2,removeWords,sword2)
corp2
tdm2 <- TermDocumentMatrix(corp1)
tdm2
m2 <- as.matrix(tdm2)
m2
colnames(m2) <- c(1:4)
m2
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,removePunctuation)
#corp2 <- tm_map(corp2,PlainTextDocument)
sword2 <- c(stopwords('en'),"and","but",'not')
corp2 <- tm_map(corp2,removeWords,sword2)
corp2
tdm2 <- TermDocumentMatrix(corp2)
tdm2
m2 <- as.matrix(tdm2)
m2
colnames(m2) <- c(1:4)
m2
freq1 <- sort(rowSums(m2),decreasing=T)
head(freq1,20)
freq2 <- sort(colSums(m2),decreasing=T)
head(freq2,20)
findFreqTerms(tdm2,2)
palete <- brewer.pal(7,"Set3")
wordcloud(names(freq1),freq=freq1,scale=c(5,1),min.freq=1,colors=palete,
random.order=F, random.color=T)
legend(0.3,1 ,"tm Package Test #1 ",cex=1,
fill=NA,border=NA,bg="white" ,
text.col="red",text.font=2,box.col="red")
barplot(freq1,main="tm package test #2",las=2,ylim=c(0,5))
data1 <- readLines("steve.txt")
data1
corp1 <- Corpus(VectorSource(data1))
corp1
inspect(corp1)
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,removePunctuation)
corp2 <- tm_map(corp2,PlainTextDocument)
stopword2 <- c(stopwords('en'),"and","but")
corp2 <- tm_map(corp2,removeWords,stopword2)
corp3 <- TermDocumentMatrix(corp2,control=list(wordLengths=c(1,Inf)))
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,removePunctuation)
#corp2 <- tm_map(corp2,PlainTextDocument)
stopword2 <- c(stopwords('en'),"and","but")
corp2 <- tm_map(corp2,removeWords,stopword2)
corp3 <- TermDocumentMatrix(corp2,control=list(wordLengths=c(1,Inf)))
corp3
library(rJava)
corp2 <- tm_map(corp2,PlainTextDocument)
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,PlainTextDocument)
stopword2 <- c(stopwords('en'),"and","but")
corp2 <- tm_map(corp2,removeWords,stopword2)
corp3 <- TermDocumentMatrix(corp2,control=list(wordLengths=c(1,Inf)))
corp2 <- tm_map(corp1,stripWhitespace)
corp2 <- tm_map(corp2,tolower)
corp2 <- tm_map(corp2,removeNumbers)
corp2 <- tm_map(corp2,removePunctuation)
#library(rJava)
#corp2 <- tm_map(corp2,PlainTextDocument)
stopword2 <- c(stopwords('en'),"and","but")
corp2 <- tm_map(corp2,removeWords,stopword2)
corp3 <- TermDocumentMatrix(corp2,control=list(wordLengths=c(1,Inf)))
corp3
findFreqTerms(corp3,10)
findAssocs(corp3,"apple",0.5)
corp4 <- as.matrix(corp3)
corp4
freq1 <- sort(rowSums(corp4),decreasing=T)
freq2 <- sort(colSums(corp4),decreasing=T)
head(freq2,20)
dim(corp)
dim(corp4)
colnames(corp4) <- c(1:59)
freq2 <- sort(colSums(corp4),decreasing=T)
wordcloud(names(freq1),freq=freq1,scale=c(5,1),min.freq=5,colors=palete,
random.order=F, random.color=T)
legend(0.3,1 ,"스티브 잡스 연설문 분석",cex=1,fill=NA,
border=NA,bg="white" , text.col="red",text.font=2,box.col="red")
wordcloud(names(freq1),freq=freq1,scale=c(5,1),min.freq=3,colors=palete,
random.order=F, random.color=T)
wordcloud(names(freq1),freq=freq1,scale=c(5,1),min.freq=2,colors=palete,
random.order=F, random.color=T)
legend(0.3,1 ,"스티브 잡스 연설문 분석",cex=1,fill=NA,
border=NA,bg="white" , text.col="red",text.font=2,box.col="red")
wordcloud(names(freq1),freq=freq1,scale=c(6,1),min.freq=2,colors=palete,
random.order=F, random.color=T)
legend(0.3,1 ,"스티브 잡스 연설문 분석",cex=1,fill=NA,
border=NA,bg="white" , text.col="red",text.font=2,box.col="red")
head(sort(wordcount, decreasing=T),30)
top10 <- head(sort(wordcount, decreasing=T),10)
pie(top10,main="제주도 추천 여행 코스 TOP 10")
library(ggplot2)
top10
str(top10)
top10[1]
df_top <- as.data.frame(top10)
df_top
ggplot(df_top, aes(x=rev, y=Freq)) +
geom_bar(stat='identity', width=1)
ggplot(df_top, aes(x='', y=Freq)) +
facet_grid(facets = ~rev) +
geom_bar(stat='identity', width=1)
ggplot(df_top, aes(x='', y=Freq, fill=rev)) +
facet_grid(facets = ~rev) +
geom_bar(stat='identity', width=1)
ggplot(df_top, aes(x='', y=Freq, fill=rev)) +
#facet_grid(facets = ~rev) +
geom_bar(stat='identity', width=1)
ggplot(df_top, aes(x='', y=Freq, fill=rev)) +
geom_bar(stat='identity', width=1) +
coord_polar(theta="y")
pct <- round(top10/sum(top10) * 100 ,1)
names(top10)
lab <- paste(names(top10),"\n",pct,"%")
pie(top10,main="제주도 추천 여행 코스 TOP 10",col=rainbow(10),
cex=0.8,labels = lab)
